{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing..\n",
      "[0.003928809426724911, -0.007745366543531418, 0.03407980501651764]\n"
     ]
    }
   ],
   "source": [
    "from scripts_huggingface import huggingface_embed_local\n",
    "embedding_model = 'BAAI/bge-large-en-v1.5'\n",
    "embeddings = huggingface_embed_local(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AStraDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_astradb import astradb_start\n",
    "collection_name = \"project1\"\n",
    "vstore = astradb_start(embeddings, collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_chat import chat_start\n",
    "llm = chat_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# personality = \"\"\"\n",
    "# You are a scientist that draws inspiration from great thinkers of the past\n",
    "# to craft well-thought answers to user questions. Use the provided context as the basis\n",
    "# for your answers and do not make up new reasoning paths - just mix-and-match what you are given.\n",
    "# Your answers must be concise and to the point, and refrain from answering about other topics than biophysics.\n",
    "# \"\"\"\n",
    "\n",
    "# personality = \"\"\"\n",
    "# You are a recruiter that draws inspiration from successful hiring strategies of the past\n",
    "# to craft well-thought responses to candidate inquiries. Use the provided context as the basis\n",
    "# for your responses and do not make up new reasoning paths - just mix-and-match what you are given.\n",
    "# Your answers must be concise and to the point, and refrain from answering about other topics than recruitment and human resources.\n",
    "# \"\"\"\n",
    "personality = \"\"\"\n",
    "You are a data science professional that draws inspiration from successful data-driven projects of the past\n",
    "to craft well-thought responses to inquiries.\n",
    "Your answers must be concise and to the point, and refrain from answering about other topics than data science and analytics.\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts_chat import chat_template_1\n",
    "chain = chat_template_1(llm, vstore, personality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobdescription =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "To present this project on GitHub, I would suggest the following structure and content:\n",
      "\n",
      "1. **README.md**: This is the main file where you provide an overview of the project, its objectives, and how to run it. Here's an example:\n",
      "\n",
      "```markdown\n",
      "# Project Title\n",
      "\n",
      "This project aims to perform feature selection using forward selection method on a given dataset. The goal is to find the best subset of features that maximizes the F1 score and ROC_AUC score.\n",
      "\n",
      "## Table of Contents\n",
      "1. [Installation](#installation)\n",
      "2. [Usage](#usage)\n",
      "3. [Results](#results)\n",
      "4. [References](#references)\n",
      "\n",
      "## Installation\n",
      "...\n",
      "\n",
      "## Usage\n",
      "...\n",
      "\n",
      "## Results\n",
      "The best F1 score was %.2f with feature subset (indices): %s and corresponding names: %s. The best ROC_AUC score was %.2f with feature subset (indices): %s and corresponding names: %s.\n",
      "\n",
      "## References\n",
      "...\n",
      "```\n",
      "\n",
      "2. **Python Script(s)**: You can include the Python script(s) used for data preprocessing, feature selection, and model evaluation. Make sure to include comments in your code to explain what each part does.\n",
      "\n",
      "3. **Notebook(s)**: If you have Jupyter notebooks, you can include them to show your work, explanations, and visualizations.\n",
      "\n",
      "4. **PDF Report**: If there's a PDF report, you can include it in a separate folder or link it in the README file. In your case, you can include the `project1.pdf` file.\n",
      "\n",
      "5. **Data**: If possible, include a sample of the data or use a publicly available dataset and link it in your README file.\n",
      "\n",
      "6. **License**: If necessary, include a license for your project.\n",
      "\n",
      "Remember, the goal is to make your project as understandable and reproducible as possible."
     ]
    }
   ],
   "source": [
    "user_input = '''\n",
    "\n",
    " How would you present the information you have as a project that will be pu in github ?\n",
    "'''\n",
    "for s in chain.stream(user_input):\n",
    "    print(s, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
